{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92fd1fb8",
   "metadata": {},
   "source": [
    "# Coding Block 4 - Automated model and hyperparameter tuning with AutoGluon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39695e0",
   "metadata": {},
   "source": [
    "### Load the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2b0c94e",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-09-20T20:03:00.442022Z",
     "iopub.status.busy": "2021-09-20T20:03:00.441258Z",
     "iopub.status.idle": "2021-09-20T20:03:01.852024Z",
     "shell.execute_reply": "2021-09-20T20:03:01.851352Z",
     "shell.execute_reply.started": "2021-09-20T19:54:12.026788Z"
    },
    "papermill": {
     "duration": 1.435807,
     "end_time": "2021-09-20T20:03:01.852223",
     "exception": false,
     "start_time": "2021-09-20T20:03:00.416416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n...\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install autogluon.tabular  > /dev/null 2>&1\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "# AutoML\n",
    "from autogluon.tabular import TabularPredictor\n",
    "'''\n",
    "...\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aaae9e8",
   "metadata": {},
   "source": [
    "### Read the dataset \n",
    "You can also compare processed and non-processed data. The autogluon library will do some preprocessing as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1775d95",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-09-20T20:03:01.895944Z",
     "iopub.status.busy": "2021-09-20T20:03:01.895175Z",
     "iopub.status.idle": "2021-09-20T20:03:05.794695Z",
     "shell.execute_reply": "2021-09-20T20:03:05.795244Z",
     "shell.execute_reply.started": "2021-09-20T19:54:12.050571Z"
    },
    "papermill": {
     "duration": 3.924865,
     "end_time": "2021-09-20T20:03:05.795452",
     "exception": false,
     "start_time": "2021-09-20T20:03:01.870587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "diab=pd.read_csv('C:\\\\Users\\\\v.weber\\\\Documents\\\\000 Master Wirtschaftsinformatik FU Berlin\\\\I\\\\Applied Analytics\\\\github stuff\\\\fork\\\\Applied-Analytics\\\\data\\\\diabetes_data_cleaned.csv')\n",
    "diab = diab.drop(columns=['outlier_z_score', 'outlier_Tukey'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5937d7",
   "metadata": {},
   "source": [
    "### Use the Autogluon library\n",
    "Use the library autogluon for automated hyperparametertuning and model benchmarking. The fit function of the TabularPredictor object allows for setting the option: <br>\n",
    "<i>presets = {‘best_quality’, ‘high_quality’, ‘good_quality’, ‘medium_quality’, ‘experimental_quality’, ‘optimize_for_deployment’, ‘interpretable’, ‘ignore_text’}</i> <br>\n",
    "\n",
    "medium_quality can limit the depths of hyperparameter optimization.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "878256be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20250320_140702\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.9.21\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          16\n",
      "Memory Avail:       44.39 GB / 63.73 GB (69.6%)\n",
      "Disk Space Avail:   1508.06 GB / 1888.04 GB (79.9%)\n",
      "===================================================\n",
      "Presets specified: ['good_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Note: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.\n",
      "\tYou can avoid this risk by setting `save_bag_folds=True`.\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 75s of the 300s of remaining time (25%).\n",
      "\t\tContext path: \"AutogluonModels\\ag-20250320_140702\\ds_sub_fit\\sub_fit_ho\"\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                           model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0            XGBoost_BAG_L1_FULL       0.790698   0.778592    accuracy        0.000000            NaN  0.988041                 0.000000                     NaN           0.988041            1       True          9\n",
      "1           LightGBM_BAG_L1_FULL       0.779070   0.788856    accuracy        0.000000            NaN  0.098264                 0.000000                     NaN           0.098264            1       True          2\n",
      "2           LightGBM_BAG_L2_FULL       0.744186   0.813783    accuracy        0.333376            NaN  5.724327                 0.000000                     NaN           0.133091            2       True         12\n",
      "3           CatBoost_BAG_L1_FULL       0.732558   0.785924    accuracy        0.000000            NaN  0.815699                 0.000000                     NaN           0.815699            1       True          5\n",
      "4         LightGBMXT_BAG_L1_FULL       0.732558   0.791789    accuracy        0.003548            NaN  0.530252                 0.003548                     NaN           0.530252            1       True          1\n",
      "5     ExtraTreesGini_BAG_L1_FULL       0.732558   0.769795    accuracy        0.066642       0.069897  0.665729                 0.066642                0.069897           0.665729            1       True          6\n",
      "6   RandomForestGini_BAG_L1_FULL       0.732558   0.752199    accuracy        0.113797       0.066693  0.830018                 0.113797                0.066693           0.830018            1       True          3\n",
      "7   RandomForestEntr_BAG_L2_FULL       0.732558   0.802053    accuracy        0.416535            NaN  6.139169                 0.083159                0.068118           0.547932            2       True         14\n",
      "8   RandomForestGini_BAG_L2_FULL       0.720930   0.791789    accuracy        0.449920            NaN  6.306537                 0.116544                0.084004           0.715301            2       True         13\n",
      "9     ExtraTreesEntr_BAG_L1_FULL       0.709302   0.758065    accuracy        0.068202       0.066900  0.515826                 0.068202                0.066900           0.515826            1       True          7\n",
      "10      WeightedEnsemble_L2_FULL       0.709302   0.810850    accuracy        0.081871            NaN  2.247599                 0.000000                     NaN           0.080458            2       True         10\n",
      "11      WeightedEnsemble_L3_FULL       0.709302   0.821114    accuracy        0.350040            NaN  5.854834                 0.000000                     NaN           0.119900            3       True         15\n",
      "12        LightGBMXT_BAG_L2_FULL       0.709302   0.821114    accuracy        0.350040            NaN  5.734934                 0.016664                     NaN           0.143698            2       True         11\n",
      "13   NeuralNetFastAI_BAG_L1_FULL       0.697674   0.807918    accuracy        0.015229            NaN  0.685712                 0.015229                     NaN           0.685712            1       True          8\n",
      "14  RandomForestEntr_BAG_L1_FULL       0.697674   0.740469    accuracy        0.065958       0.067127  0.461694                 0.065958                0.067127           0.461694            1       True          4\n",
      "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
      "\t85s\t = DyStack   runtime |\t215s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=0.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
      "Beginning AutoGluon training ... Time limit = 215s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20250320_140702\"\n",
      "Train Data Rows:    768\n",
      "Train Data Columns: 8\n",
      "Label Column:       Outcome\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    45152.80 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.05 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 2 | ['BMI', 'DiabetesPedigreeFunction']\n",
      "\t\t('int', [])   : 6 | ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 2 | ['BMI', 'DiabetesPedigreeFunction']\n",
      "\t\t('int', [])   : 6 | ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t8 features in original data used to generate 8 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.05 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 215.07s of the 215.05s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.00%)\n",
      "\t0.7891\t = Validation score   (accuracy)\n",
      "\t1.27s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 204.45s of the 204.43s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.00%)\n",
      "\t0.7799\t = Validation score   (accuracy)\n",
      "\t1.37s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 195.39s of the 195.38s of remaining time.\n",
      "\t0.7526\t = Validation score   (accuracy)\n",
      "\t0.75s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 194.51s of the 194.49s of remaining time.\n",
      "\t0.7422\t = Validation score   (accuracy)\n",
      "\t0.54s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 193.84s of the 193.83s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.01%)\n",
      "\t0.7917\t = Validation score   (accuracy)\n",
      "\t3.03s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 183.47s of the 183.45s of remaining time.\n",
      "\t0.7708\t = Validation score   (accuracy)\n",
      "\t0.73s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 182.6s of the 182.59s of remaining time.\n",
      "\t0.7578\t = Validation score   (accuracy)\n",
      "\t0.52s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 181.95s of the 181.94s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.00%)\n",
      "\t0.7852\t = Validation score   (accuracy)\n",
      "\t9.6s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 164.99s of the 164.97s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.01%)\n",
      "\t0.7734\t = Validation score   (accuracy)\n",
      "\t1.58s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 155.24s of the 155.23s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.00%)\n",
      "\t0.7891\t = Validation score   (accuracy)\n",
      "\t13.64s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 133.73s of the 133.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.01%)\n",
      "\t0.7604\t = Validation score   (accuracy)\n",
      "\t2.61s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 215.07s of the 123.57s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 1.0}\n",
      "\t0.7917\t = Validation score   (accuracy)\n",
      "\t0.15s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 91.83s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 14283.0 rows/s (96 batch size)\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t0.27s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t0.14s\t = Training   runtime\n",
      "Fitting model: RandomForestGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.75s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.54s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\t0.29s\t = Training   runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.73s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.52s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 8.\n",
      "\t0.54s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\t0.55s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetTorch_BAG_L1_FULL ...\n",
      "\t2.21s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\t0.32s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 1.0}\n",
      "\t0.15s\t = Training   runtime\n",
      "Updated best model to \"CatBoost_BAG_L1_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"CatBoost_BAG_L1_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 5.51s ... Best model: \"CatBoost_BAG_L1_FULL\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20250320_140702\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training and hyperparameter tuning completed.\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "# Define the target variable\n",
    "target = 'Outcome'\n",
    "\n",
    "# Perform automated hyperparameter tuning\n",
    "predictor = TabularPredictor(label=target).fit(\n",
    "    train_data=diab, \n",
    "    presets='good_quality',  # Adjusted for faster training\n",
    "    time_limit=300  # 5-minute time limit\n",
    ")\n",
    "\n",
    "print(\"Model training and hyperparameter tuning completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d414ebe",
   "metadata": {},
   "source": [
    "### Show the leaderboard\n",
    "TabularPredictor objects from Autogluon provide a function \"leaderboard\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c06190c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           model  score_val eval_metric  pred_time_val  \\\n",
      "0            WeightedEnsemble_L2   0.791667    accuracy       0.006721   \n",
      "1                CatBoost_BAG_L1   0.791667    accuracy       0.006721   \n",
      "2              LightGBMXT_BAG_L1   0.789062    accuracy       0.034144   \n",
      "3          NeuralNetTorch_BAG_L1   0.789062    accuracy       0.084738   \n",
      "4         NeuralNetFastAI_BAG_L1   0.785156    accuracy       0.086087   \n",
      "5                LightGBM_BAG_L1   0.779948    accuracy       0.025446   \n",
      "6                 XGBoost_BAG_L1   0.773438    accuracy       0.034424   \n",
      "7          ExtraTreesGini_BAG_L1   0.770833    accuracy       0.066921   \n",
      "8           LightGBMLarge_BAG_L1   0.760417    accuracy       0.033513   \n",
      "9          ExtraTreesEntr_BAG_L1   0.757812    accuracy       0.066660   \n",
      "10       RandomForestGini_BAG_L1   0.752604    accuracy       0.068281   \n",
      "11       RandomForestEntr_BAG_L1   0.742188    accuracy       0.067895   \n",
      "12    ExtraTreesEntr_BAG_L1_FULL        NaN    accuracy       0.066660   \n",
      "13    ExtraTreesGini_BAG_L1_FULL        NaN    accuracy       0.066921   \n",
      "14  RandomForestEntr_BAG_L1_FULL        NaN    accuracy       0.067895   \n",
      "15  RandomForestGini_BAG_L1_FULL        NaN    accuracy       0.068281   \n",
      "16           XGBoost_BAG_L1_FULL        NaN    accuracy            NaN   \n",
      "17      WeightedEnsemble_L2_FULL        NaN    accuracy            NaN   \n",
      "18    NeuralNetTorch_BAG_L1_FULL        NaN    accuracy            NaN   \n",
      "19   NeuralNetFastAI_BAG_L1_FULL        NaN    accuracy            NaN   \n",
      "20          LightGBM_BAG_L1_FULL        NaN    accuracy            NaN   \n",
      "21        LightGBMXT_BAG_L1_FULL        NaN    accuracy            NaN   \n",
      "22     LightGBMLarge_BAG_L1_FULL        NaN    accuracy            NaN   \n",
      "23          CatBoost_BAG_L1_FULL        NaN    accuracy            NaN   \n",
      "\n",
      "     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
      "0    3.175037                0.000000           0.149816            2   \n",
      "1    3.025221                0.006721           3.025221            1   \n",
      "2    1.273152                0.034144           1.273152            1   \n",
      "3   13.635181                0.084738          13.635181            1   \n",
      "4    9.602506                0.086087           9.602506            1   \n",
      "5    1.365520                0.025446           1.365520            1   \n",
      "6    1.583464                0.034424           1.583464            1   \n",
      "7    0.726739                0.066921           0.726739            1   \n",
      "8    2.608173                0.033513           2.608173            1   \n",
      "9    0.518988                0.066660           0.518988            1   \n",
      "10   0.748124                0.068281           0.748124            1   \n",
      "11   0.537102                0.067895           0.537102            1   \n",
      "12   0.518988                0.066660           0.518988            1   \n",
      "13   0.726739                0.066921           0.726739            1   \n",
      "14   0.537102                0.067895           0.537102            1   \n",
      "15   0.748124                0.068281           0.748124            1   \n",
      "16   0.549552                     NaN           0.549552            1   \n",
      "17   0.436139                     NaN           0.149816            2   \n",
      "18   2.212013                     NaN           2.212013            1   \n",
      "19   0.537195                     NaN           0.537195            1   \n",
      "20   0.138481                     NaN           0.138481            1   \n",
      "21   0.271954                     NaN           0.271954            1   \n",
      "22   0.317762                     NaN           0.317762            1   \n",
      "23   0.286323                     NaN           0.286323            1   \n",
      "\n",
      "    can_infer  fit_order  \n",
      "0       False         12  \n",
      "1       False          5  \n",
      "2       False          1  \n",
      "3       False         10  \n",
      "4       False          8  \n",
      "5       False          2  \n",
      "6       False          9  \n",
      "7        True          6  \n",
      "8       False         11  \n",
      "9        True          7  \n",
      "10       True          3  \n",
      "11       True          4  \n",
      "12       True         19  \n",
      "13       True         18  \n",
      "14       True         16  \n",
      "15       True         15  \n",
      "16       True         21  \n",
      "17       True         24  \n",
      "18       True         22  \n",
      "19       True         20  \n",
      "20       True         14  \n",
      "21       True         13  \n",
      "22       True         23  \n",
      "23       True         17  \n"
     ]
    }
   ],
   "source": [
    "# Display the leaderboard of trained models\n",
    "leaderboard = predictor.leaderboard(silent=True)\n",
    "print(leaderboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a513f67a",
   "metadata": {},
   "source": [
    "### Show the feature importance table\n",
    "The TabularPredictor class from Autogluon also provides a function \"feature_importance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c29e109",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\v.weber\\AppData\\Local\\Temp\\ipykernel_31492\\3175031045.py:2: DeprecationWarning: `get_model_names` has been deprecated and will be removed in version 1.2. Please use `model_names` instead. This will raise an error in the future!\n",
      "  for model in predictor.get_model_names():\n",
      "Computing feature importance via permutation shuffling for 8 features using 768 rows with 5 shuffle sets...\n",
      "Computing feature importance via permutation shuffling for 8 features using 768 rows with 5 shuffle sets...\n",
      "Computing feature importance via permutation shuffling for 8 features using 768 rows with 5 shuffle sets...\n",
      "\t3.51s\t= Expected runtime (0.7s per shuffle set)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance for model: LightGBMXT_BAG_L1\n",
      "Skipping model LightGBMXT_BAG_L1 due to error: 'NoneType' object has no attribute 'predict'\n",
      "Feature importance for model: LightGBM_BAG_L1\n",
      "Skipping model LightGBM_BAG_L1 due to error: 'NoneType' object has no attribute 'predict'\n",
      "Feature importance for model: RandomForestGini_BAG_L1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.51s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n",
      "Computing feature importance via permutation shuffling for 8 features using 768 rows with 5 shuffle sets...\n",
      "\t3.77s\t= Expected runtime (0.75s per shuffle set)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          importance    stddev       p_value  n  p99_high  \\\n",
      "Glucose                     0.200260  0.009040  4.969023e-07  5  0.218874   \n",
      "BMI                         0.089323  0.008214  8.487297e-06  5  0.106237   \n",
      "Age                         0.072917  0.008079  1.779405e-05  5  0.089552   \n",
      "DiabetesPedigreeFunction    0.051302  0.007400  5.054148e-05  5  0.066539   \n",
      "Insulin                     0.044271  0.006107  4.238092e-05  5  0.056846   \n",
      "Pregnancies                 0.032292  0.006536  1.909038e-04  5  0.045750   \n",
      "SkinThickness               0.029687  0.003613  2.581633e-05  5  0.037127   \n",
      "BloodPressure               0.014583  0.002140  5.403493e-05  5  0.018989   \n",
      "\n",
      "                           p99_low  \n",
      "Glucose                   0.181647  \n",
      "BMI                       0.072409  \n",
      "Age                       0.056281  \n",
      "DiabetesPedigreeFunction  0.036065  \n",
      "Insulin                   0.031696  \n",
      "Pregnancies               0.018833  \n",
      "SkinThickness             0.022248  \n",
      "BloodPressure             0.010178  \n",
      "Feature importance for model: RandomForestEntr_BAG_L1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.53s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n",
      "Computing feature importance via permutation shuffling for 8 features using 768 rows with 5 shuffle sets...\n",
      "Computing feature importance via permutation shuffling for 8 features using 768 rows with 5 shuffle sets...\n",
      "\t3.05s\t= Expected runtime (0.61s per shuffle set)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          importance    stddev       p_value  n  p99_high  \\\n",
      "Glucose                     0.199479  0.010871  1.054130e-06  5  0.221862   \n",
      "Age                         0.085417  0.008163  9.887380e-06  5  0.102224   \n",
      "BMI                         0.083854  0.009326  1.806108e-05  5  0.103057   \n",
      "DiabetesPedigreeFunction    0.055208  0.004924  7.512731e-06  5  0.065347   \n",
      "Insulin                     0.047135  0.005779  2.658423e-05  5  0.059035   \n",
      "Pregnancies                 0.029167  0.006419  2.641593e-04  5  0.042383   \n",
      "SkinThickness               0.027604  0.001426  8.524242e-07  5  0.030541   \n",
      "BloodPressure               0.012760  0.001931  6.109038e-05  5  0.016737   \n",
      "\n",
      "                           p99_low  \n",
      "Glucose                   0.177096  \n",
      "Age                       0.068610  \n",
      "BMI                       0.064652  \n",
      "DiabetesPedigreeFunction  0.045070  \n",
      "Insulin                   0.035236  \n",
      "Pregnancies               0.015951  \n",
      "SkinThickness             0.024667  \n",
      "BloodPressure             0.008784  \n",
      "Feature importance for model: CatBoost_BAG_L1\n",
      "Skipping model CatBoost_BAG_L1 due to error: 'NoneType' object has no attribute 'predict_proba'\n",
      "Feature importance for model: ExtraTreesGini_BAG_L1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.57s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n",
      "Computing feature importance via permutation shuffling for 8 features using 768 rows with 5 shuffle sets...\n",
      "\t3.55s\t= Expected runtime (0.71s per shuffle set)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          importance    stddev       p_value  n  p99_high  \\\n",
      "Glucose                     0.188542  0.011514  1.660978e-06  5  0.212250   \n",
      "BMI                         0.079167  0.004640  1.409898e-06  5  0.088721   \n",
      "Pregnancies                 0.073698  0.005493  3.677434e-06  5  0.085009   \n",
      "Age                         0.071354  0.003949  1.121664e-06  5  0.079486   \n",
      "DiabetesPedigreeFunction    0.064062  0.005779  7.862404e-06  5  0.075962   \n",
      "SkinThickness               0.049740  0.003370  2.514336e-06  5  0.056679   \n",
      "Insulin                     0.048698  0.001485  1.035246e-07  5  0.051755   \n",
      "BloodPressure               0.041406  0.001698  3.383746e-07  5  0.044902   \n",
      "\n",
      "                           p99_low  \n",
      "Glucose                   0.164833  \n",
      "BMI                       0.069612  \n",
      "Pregnancies               0.062387  \n",
      "Age                       0.063222  \n",
      "DiabetesPedigreeFunction  0.052163  \n",
      "SkinThickness             0.042800  \n",
      "Insulin                   0.045641  \n",
      "BloodPressure             0.037911  \n",
      "Feature importance for model: ExtraTreesEntr_BAG_L1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.62s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n",
      "Computing feature importance via permutation shuffling for 8 features using 768 rows with 5 shuffle sets...\n",
      "Computing feature importance via permutation shuffling for 8 features using 768 rows with 5 shuffle sets...\n",
      "Computing feature importance via permutation shuffling for 8 features using 768 rows with 5 shuffle sets...\n",
      "Computing feature importance via permutation shuffling for 8 features using 768 rows with 5 shuffle sets...\n",
      "Computing feature importance via permutation shuffling for 8 features using 768 rows with 5 shuffle sets...\n",
      "Computing feature importance via permutation shuffling for 8 features using 768 rows with 5 shuffle sets...\n",
      "\t0.23s\t= Expected runtime (0.05s per shuffle set)\n",
      "\t0.11s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n",
      "Computing feature importance via permutation shuffling for 8 features using 768 rows with 5 shuffle sets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          importance    stddev       p_value  n  p99_high  \\\n",
      "Glucose                     0.191927  0.015368  4.890914e-06  5  0.223570   \n",
      "BMI                         0.081250  0.006678  5.425669e-06  5  0.094999   \n",
      "Pregnancies                 0.068229  0.004179  1.680202e-06  5  0.076833   \n",
      "Age                         0.067448  0.004992  3.575454e-06  5  0.077727   \n",
      "DiabetesPedigreeFunction    0.059635  0.007503  2.943647e-05  5  0.075083   \n",
      "SkinThickness               0.046875  0.002762  1.440086e-06  5  0.052562   \n",
      "Insulin                     0.043750  0.001975  4.967079e-07  5  0.047816   \n",
      "BloodPressure               0.035937  0.002365  2.239074e-06  5  0.040808   \n",
      "\n",
      "                           p99_low  \n",
      "Glucose                   0.160284  \n",
      "BMI                       0.067501  \n",
      "Pregnancies               0.059625  \n",
      "Age                       0.057169  \n",
      "DiabetesPedigreeFunction  0.044188  \n",
      "SkinThickness             0.041188  \n",
      "Insulin                   0.039684  \n",
      "BloodPressure             0.031067  \n",
      "Feature importance for model: NeuralNetFastAI_BAG_L1\n",
      "Skipping model NeuralNetFastAI_BAG_L1 due to error: 'NoneType' object has no attribute 'dls'\n",
      "Feature importance for model: XGBoost_BAG_L1\n",
      "Skipping model XGBoost_BAG_L1 due to error: 'NoneType' object has no attribute 'set_params'\n",
      "Feature importance for model: NeuralNetTorch_BAG_L1\n",
      "Skipping model NeuralNetTorch_BAG_L1 due to error: 'NoneType' object has no attribute 'predict'\n",
      "Feature importance for model: LightGBMLarge_BAG_L1\n",
      "Skipping model LightGBMLarge_BAG_L1 due to error: 'NoneType' object has no attribute 'predict'\n",
      "Feature importance for model: WeightedEnsemble_L2\n",
      "Skipping model WeightedEnsemble_L2 due to error: 'NoneType' object has no attribute 'predict_proba'\n",
      "Feature importance for model: LightGBMXT_BAG_L1_FULL\n",
      "                          importance    stddev   p_value  n  p99_high  \\\n",
      "Glucose                     0.126302  0.012180  0.000010  5  0.151381   \n",
      "BMI                         0.033854  0.006828  0.000188  5  0.047913   \n",
      "Age                         0.021094  0.005076  0.000373  5  0.031546   \n",
      "DiabetesPedigreeFunction    0.007292  0.005009  0.015615  5  0.017606   \n",
      "Insulin                     0.003906  0.002912  0.019971  5  0.009901   \n",
      "Pregnancies                 0.003385  0.003268  0.040735  5  0.010115   \n",
      "SkinThickness               0.002344  0.002668  0.060502  5  0.007838   \n",
      "BloodPressure               0.001563  0.001426  0.035242  5  0.004499   \n",
      "\n",
      "                           p99_low  \n",
      "Glucose                   0.101224  \n",
      "BMI                       0.019795  \n",
      "Age                       0.010641  \n",
      "DiabetesPedigreeFunction -0.003022  \n",
      "Insulin                  -0.002089  \n",
      "Pregnancies              -0.003344  \n",
      "SkinThickness            -0.003151  \n",
      "BloodPressure            -0.001374  \n",
      "Feature importance for model: LightGBM_BAG_L1_FULL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.37s\t= Expected runtime (0.07s per shuffle set)\n",
      "\t0.12s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n",
      "Computing feature importance via permutation shuffling for 8 features using 768 rows with 5 shuffle sets...\n",
      "\t5.29s\t= Expected runtime (1.06s per shuffle set)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          importance    stddev       p_value  n  p99_high  \\\n",
      "Glucose                     0.181250  0.006665  2.190001e-07  5  0.194973   \n",
      "Age                         0.096094  0.006204  2.072993e-06  5  0.108867   \n",
      "BMI                         0.088802  0.003370  2.485191e-07  5  0.095742   \n",
      "DiabetesPedigreeFunction    0.045312  0.003729  5.452319e-06  5  0.052990   \n",
      "Pregnancies                 0.023958  0.004377  1.279331e-04  5  0.032971   \n",
      "Insulin                     0.018750  0.002998  7.579241e-05  5  0.024922   \n",
      "SkinThickness               0.014844  0.005257  1.609119e-03  5  0.025668   \n",
      "BloodPressure               0.013281  0.001698  3.135273e-05  5  0.016777   \n",
      "\n",
      "                           p99_low  \n",
      "Glucose                   0.167527  \n",
      "Age                       0.083320  \n",
      "BMI                       0.081862  \n",
      "DiabetesPedigreeFunction  0.037635  \n",
      "Pregnancies               0.014946  \n",
      "Insulin                   0.012578  \n",
      "SkinThickness             0.004020  \n",
      "BloodPressure             0.009786  \n",
      "Feature importance for model: RandomForestGini_BAG_L1_FULL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.59s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n",
      "Computing feature importance via permutation shuffling for 8 features using 768 rows with 5 shuffle sets...\n",
      "\t3.64s\t= Expected runtime (0.73s per shuffle set)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          importance    stddev       p_value  n  p99_high  \\\n",
      "Glucose                     0.200260  0.009040  4.969023e-07  5  0.218874   \n",
      "BMI                         0.089323  0.008214  8.487297e-06  5  0.106237   \n",
      "Age                         0.072917  0.008079  1.779405e-05  5  0.089552   \n",
      "DiabetesPedigreeFunction    0.051302  0.007400  5.054148e-05  5  0.066539   \n",
      "Insulin                     0.044271  0.006107  4.238092e-05  5  0.056846   \n",
      "Pregnancies                 0.032292  0.006536  1.909038e-04  5  0.045750   \n",
      "SkinThickness               0.029687  0.003613  2.581633e-05  5  0.037127   \n",
      "BloodPressure               0.014583  0.002140  5.403493e-05  5  0.018989   \n",
      "\n",
      "                           p99_low  \n",
      "Glucose                   0.181647  \n",
      "BMI                       0.072409  \n",
      "Age                       0.056281  \n",
      "DiabetesPedigreeFunction  0.036065  \n",
      "Insulin                   0.031696  \n",
      "Pregnancies               0.018833  \n",
      "SkinThickness             0.022248  \n",
      "BloodPressure             0.010178  \n",
      "Feature importance for model: RandomForestEntr_BAG_L1_FULL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.55s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n",
      "Computing feature importance via permutation shuffling for 8 features using 768 rows with 5 shuffle sets...\n",
      "\t0.0s\t= Expected runtime (0.0s per shuffle set)\n",
      "\t0.07s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n",
      "Computing feature importance via permutation shuffling for 8 features using 768 rows with 5 shuffle sets...\n",
      "\t2.99s\t= Expected runtime (0.6s per shuffle set)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          importance    stddev       p_value  n  p99_high  \\\n",
      "Glucose                     0.199479  0.010871  1.054130e-06  5  0.221862   \n",
      "Age                         0.085417  0.008163  9.887380e-06  5  0.102224   \n",
      "BMI                         0.083854  0.009326  1.806108e-05  5  0.103057   \n",
      "DiabetesPedigreeFunction    0.055208  0.004924  7.512731e-06  5  0.065347   \n",
      "Insulin                     0.047135  0.005779  2.658423e-05  5  0.059035   \n",
      "Pregnancies                 0.029167  0.006419  2.641593e-04  5  0.042383   \n",
      "SkinThickness               0.027604  0.001426  8.524242e-07  5  0.030541   \n",
      "BloodPressure               0.012760  0.001931  6.109038e-05  5  0.016737   \n",
      "\n",
      "                           p99_low  \n",
      "Glucose                   0.177096  \n",
      "Age                       0.068610  \n",
      "BMI                       0.064652  \n",
      "DiabetesPedigreeFunction  0.045070  \n",
      "Insulin                   0.035236  \n",
      "Pregnancies               0.015951  \n",
      "SkinThickness             0.024667  \n",
      "BloodPressure             0.008784  \n",
      "Feature importance for model: CatBoost_BAG_L1_FULL\n",
      "                          importance    stddev   p_value  n  p99_high  \\\n",
      "Glucose                     0.133333  0.016741  0.000029  5  0.167803   \n",
      "BMI                         0.016667  0.004992  0.000860  5  0.026946   \n",
      "Age                         0.008073  0.005321  0.013733  5  0.019029   \n",
      "Pregnancies                 0.006250  0.005241  0.028000  5  0.017041   \n",
      "BloodPressure               0.004167  0.001089  0.000513  5  0.006410   \n",
      "DiabetesPedigreeFunction    0.003125  0.004749  0.107558  5  0.012902   \n",
      "SkinThickness               0.001042  0.003949  0.293525  5  0.009174   \n",
      "Insulin                    -0.001302  0.003445  0.777193  5  0.005791   \n",
      "\n",
      "                           p99_low  \n",
      "Glucose                   0.098864  \n",
      "BMI                       0.006388  \n",
      "Age                      -0.002883  \n",
      "Pregnancies              -0.004541  \n",
      "BloodPressure             0.001924  \n",
      "DiabetesPedigreeFunction -0.006652  \n",
      "SkinThickness            -0.007090  \n",
      "Insulin                  -0.008395  \n",
      "Feature importance for model: ExtraTreesGini_BAG_L1_FULL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.57s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n",
      "Computing feature importance via permutation shuffling for 8 features using 768 rows with 5 shuffle sets...\n",
      "\t3.73s\t= Expected runtime (0.75s per shuffle set)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          importance    stddev       p_value  n  p99_high  \\\n",
      "Glucose                     0.188542  0.011514  1.660978e-06  5  0.212250   \n",
      "BMI                         0.079167  0.004640  1.409898e-06  5  0.088721   \n",
      "Pregnancies                 0.073698  0.005493  3.677434e-06  5  0.085009   \n",
      "Age                         0.071354  0.003949  1.121664e-06  5  0.079486   \n",
      "DiabetesPedigreeFunction    0.064062  0.005779  7.862404e-06  5  0.075962   \n",
      "SkinThickness               0.049740  0.003370  2.514336e-06  5  0.056679   \n",
      "Insulin                     0.048698  0.001485  1.035246e-07  5  0.051755   \n",
      "BloodPressure               0.041406  0.001698  3.383746e-07  5  0.044902   \n",
      "\n",
      "                           p99_low  \n",
      "Glucose                   0.164833  \n",
      "BMI                       0.069612  \n",
      "Pregnancies               0.062387  \n",
      "Age                       0.063222  \n",
      "DiabetesPedigreeFunction  0.052163  \n",
      "SkinThickness             0.042800  \n",
      "Insulin                   0.045641  \n",
      "BloodPressure             0.037911  \n",
      "Feature importance for model: ExtraTreesEntr_BAG_L1_FULL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.58s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n",
      "Computing feature importance via permutation shuffling for 8 features using 768 rows with 5 shuffle sets...\n",
      "c:\\Users\\v.weber\\AppData\\Local\\anaconda3\\envs\\aa_tuesday\\lib\\site-packages\\fastai\\learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
      "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
      "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
      "\t0.74s\t= Expected runtime (0.15s per shuffle set)\n",
      "c:\\Users\\v.weber\\AppData\\Local\\anaconda3\\envs\\aa_tuesday\\lib\\site-packages\\fastai\\learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
      "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
      "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
      "c:\\Users\\v.weber\\AppData\\Local\\anaconda3\\envs\\aa_tuesday\\lib\\site-packages\\fastai\\learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
      "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
      "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          importance    stddev       p_value  n  p99_high  \\\n",
      "Glucose                     0.191927  0.015368  4.890914e-06  5  0.223570   \n",
      "BMI                         0.081250  0.006678  5.425669e-06  5  0.094999   \n",
      "Pregnancies                 0.068229  0.004179  1.680202e-06  5  0.076833   \n",
      "Age                         0.067448  0.004992  3.575454e-06  5  0.077727   \n",
      "DiabetesPedigreeFunction    0.059635  0.007503  2.943647e-05  5  0.075083   \n",
      "SkinThickness               0.046875  0.002762  1.440086e-06  5  0.052562   \n",
      "Insulin                     0.043750  0.001975  4.967079e-07  5  0.047816   \n",
      "BloodPressure               0.035937  0.002365  2.239074e-06  5  0.040808   \n",
      "\n",
      "                           p99_low  \n",
      "Glucose                   0.160284  \n",
      "BMI                       0.067501  \n",
      "Pregnancies               0.059625  \n",
      "Age                       0.057169  \n",
      "DiabetesPedigreeFunction  0.044188  \n",
      "SkinThickness             0.041188  \n",
      "Insulin                   0.039684  \n",
      "BloodPressure             0.031067  \n",
      "Feature importance for model: NeuralNetFastAI_BAG_L1_FULL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\v.weber\\AppData\\Local\\anaconda3\\envs\\aa_tuesday\\lib\\site-packages\\fastai\\learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
      "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
      "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
      "c:\\Users\\v.weber\\AppData\\Local\\anaconda3\\envs\\aa_tuesday\\lib\\site-packages\\fastai\\learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
      "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
      "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
      "c:\\Users\\v.weber\\AppData\\Local\\anaconda3\\envs\\aa_tuesday\\lib\\site-packages\\fastai\\learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
      "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
      "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
      "\t0.51s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n",
      "Computing feature importance via permutation shuffling for 8 features using 768 rows with 5 shuffle sets...\n",
      "\t0.76s\t= Expected runtime (0.15s per shuffle set)\n",
      "\t0.17s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          importance    stddev   p_value  n  p99_high  \\\n",
      "Glucose                     0.150260  0.010917  0.000003  5  0.172739   \n",
      "BMI                         0.045833  0.006728  0.000054  5  0.059687   \n",
      "Age                         0.039063  0.007012  0.000119  5  0.053500   \n",
      "Pregnancies                 0.038281  0.005938  0.000067  5  0.050509   \n",
      "Insulin                     0.030729  0.004179  0.000040  5  0.039333   \n",
      "SkinThickness               0.020573  0.006976  0.001369  5  0.034936   \n",
      "DiabetesPedigreeFunction    0.017708  0.003518  0.000177  5  0.024952   \n",
      "BloodPressure               0.016667  0.006204  0.001933  5  0.029440   \n",
      "\n",
      "                           p99_low  \n",
      "Glucose                   0.127781  \n",
      "BMI                       0.031980  \n",
      "Age                       0.024625  \n",
      "Pregnancies               0.026054  \n",
      "Insulin                   0.022125  \n",
      "SkinThickness             0.006210  \n",
      "DiabetesPedigreeFunction  0.010465  \n",
      "BloodPressure             0.003893  \n",
      "Feature importance for model: XGBoost_BAG_L1_FULL\n",
      "                          importance    stddev       p_value  n  p99_high  \\\n",
      "Glucose                     0.242448  0.009362  2.663058e-07  5  0.261725   \n",
      "BMI                         0.127083  0.004567  1.997307e-07  5  0.136486   \n",
      "Age                         0.103646  0.008908  6.482697e-06  5  0.121987   \n",
      "DiabetesPedigreeFunction    0.080729  0.007813  1.039479e-05  5  0.096815   \n",
      "Insulin                     0.056771  0.005646  1.158366e-05  5  0.068395   \n",
      "BloodPressure               0.032031  0.006549  1.985422e-04  5  0.045516   \n",
      "SkinThickness               0.031771  0.002538  4.847326e-06  5  0.036997   \n",
      "Pregnancies                 0.031510  0.004055  3.220569e-05  5  0.039860   \n",
      "\n",
      "                           p99_low  \n",
      "Glucose                   0.223171  \n",
      "BMI                       0.117681  \n",
      "Age                       0.085305  \n",
      "DiabetesPedigreeFunction  0.064643  \n",
      "Insulin                   0.045146  \n",
      "BloodPressure             0.018546  \n",
      "SkinThickness             0.026545  \n",
      "Pregnancies               0.023160  \n",
      "Feature importance for model: NeuralNetTorch_BAG_L1_FULL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 8 features using 768 rows with 5 shuffle sets...\n",
      "\t0.84s\t= Expected runtime (0.17s per shuffle set)\n",
      "\t0.22s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n",
      "Computing feature importance via permutation shuffling for 8 features using 768 rows with 5 shuffle sets...\n",
      "\t0.38s\t= Expected runtime (0.08s per shuffle set)\n",
      "\t0.18s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          importance    stddev   p_value  n  p99_high  \\\n",
      "Glucose                     0.144271  0.013700  0.000010  5  0.172479   \n",
      "BMI                         0.030208  0.007389  0.000397  5  0.045422   \n",
      "DiabetesPedigreeFunction    0.022917  0.008266  0.001722  5  0.039936   \n",
      "Age                         0.019010  0.007457  0.002340  5  0.034365   \n",
      "Insulin                     0.017448  0.001485  0.000006  5  0.020505   \n",
      "Pregnancies                 0.014844  0.012026  0.025424  5  0.039605   \n",
      "BloodPressure               0.008073  0.006976  0.030411  5  0.022436   \n",
      "SkinThickness               0.005469  0.004358  0.024251  5  0.014441   \n",
      "\n",
      "                           p99_low  \n",
      "Glucose                   0.116063  \n",
      "BMI                       0.014995  \n",
      "DiabetesPedigreeFunction  0.005897  \n",
      "Age                       0.003656  \n",
      "Insulin                   0.014391  \n",
      "Pregnancies              -0.009917  \n",
      "BloodPressure            -0.006290  \n",
      "SkinThickness            -0.003504  \n",
      "Feature importance for model: LightGBMLarge_BAG_L1_FULL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 8 features using 768 rows with 5 shuffle sets...\n",
      "\t0.44s\t= Expected runtime (0.09s per shuffle set)\n",
      "\t0.11s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          importance    stddev       p_value  n  p99_high  \\\n",
      "Glucose                     0.254688  0.006678  5.665254e-08  5  0.268437   \n",
      "BMI                         0.110677  0.005676  8.269733e-07  5  0.122363   \n",
      "Age                         0.100781  0.005416  9.968717e-07  5  0.111932   \n",
      "DiabetesPedigreeFunction    0.057031  0.005321  8.988636e-06  5  0.067987   \n",
      "Insulin                     0.037500  0.004548  2.546018e-05  5  0.046864   \n",
      "SkinThickness               0.019271  0.003613  1.415889e-04  5  0.026710   \n",
      "Pregnancies                 0.015885  0.004640  7.825060e-04  5  0.025440   \n",
      "BloodPressure               0.010156  0.001698  9.030075e-05  5  0.013652   \n",
      "\n",
      "                           p99_low  \n",
      "Glucose                   0.240938  \n",
      "BMI                       0.098991  \n",
      "Age                       0.089630  \n",
      "DiabetesPedigreeFunction  0.046075  \n",
      "Insulin                   0.028136  \n",
      "SkinThickness             0.011831  \n",
      "Pregnancies               0.006331  \n",
      "BloodPressure             0.006661  \n",
      "Feature importance for model: WeightedEnsemble_L2_FULL\n",
      "                          importance    stddev   p_value  n  p99_high  \\\n",
      "Glucose                     0.133333  0.016741  0.000029  5  0.167803   \n",
      "BMI                         0.016667  0.004992  0.000860  5  0.026946   \n",
      "Age                         0.008073  0.005321  0.013733  5  0.019029   \n",
      "Pregnancies                 0.006250  0.005241  0.028000  5  0.017041   \n",
      "BloodPressure               0.004167  0.001089  0.000513  5  0.006410   \n",
      "DiabetesPedigreeFunction    0.003125  0.004749  0.107558  5  0.012902   \n",
      "SkinThickness               0.001042  0.003949  0.293525  5  0.009174   \n",
      "Insulin                    -0.001302  0.003445  0.777193  5  0.005791   \n",
      "\n",
      "                           p99_low  \n",
      "Glucose                   0.098864  \n",
      "BMI                       0.006388  \n",
      "Age                      -0.002883  \n",
      "Pregnancies              -0.004541  \n",
      "BloodPressure             0.001924  \n",
      "DiabetesPedigreeFunction -0.006652  \n",
      "SkinThickness            -0.007090  \n",
      "Insulin                  -0.008395  \n"
     ]
    }
   ],
   "source": [
    "# Display feature importance for each valid model\n",
    "for model in predictor.get_model_names():\n",
    "    try:\n",
    "        print(f\"Feature importance for model: {model}\")\n",
    "        # Use the training dataset (diab) for feature importance calculation\n",
    "        feature_importance = predictor.feature_importance(data=diab, model=model)\n",
    "        print(feature_importance)\n",
    "    except AttributeError as e:\n",
    "        print(f\"Skipping model {model} due to error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd378d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aa_tuesday",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 49.933279,
   "end_time": "2021-09-20T20:03:41.801824",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-09-20T20:02:51.868545",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
